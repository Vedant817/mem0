---
title: Quickstart
description: 'Get started with OpenMemory in minutes'
icon: "terminal"
iconType: "solid"
---

Get up and running with OpenMemory in under 5 minutes. Choose between hosted or self-hosted setup.

## Prerequisites

- MCP-compatible client (Claude Desktop, Cursor, Windsurf, etc.)
- OpenAI API key ([Get one here](https://platform.openai.com/api-keys))
- Docker (for self-hosted only)

## Hosted Setup (Recommended)

Get persistent memory for your AI clients with zero setup.

<Steps>
<Step title="Sign up for hosted OpenMemory">
Visit [app.openmemory.dev](https://app.openmemory.dev) and create an account to get your `OPENMEMORY_API_KEY`
</Step>

<Step title="Install OpenMemory for your client">
Replace `your-key` with your actual API key and choose your client:

<CodeGroup>
```bash Claude Desktop
npx @openmemory/install --client claude --env OPENMEMORY_API_KEY=your-key
```

```bash Cursor
npx @openmemory/install --client cursor --env OPENMEMORY_API_KEY=your-key
```

```bash Windsurf
npx @openmemory/install --client windsurf --env OPENMEMORY_API_KEY=your-key
```
</CodeGroup>
</Step>

<Step title="Start using persistent memory">
Your AI client now has shared, persistent memory across all sessions. No manual configuration needed!
</Step>
</Steps>

## What's Next?

<CardGroup cols={2}>
<Card title="Local Self-Hosted Setup" icon="server" href="#local-setup-self-hosted">
Run OpenMemory locally with Docker for complete control and privacy
</Card>

<Card title="API Reference" icon="code" href="/openmemory/integrations">
Explore MCP integration details and advanced configuration
</Card>
</CardGroup>

---

## Local Setup (Self-Hosted)

### Quick Start with Docker

Run OpenMemory locally in seconds:

```bash
export OPENAI_API_KEY=your_api_key
curl -sL https://raw.githubusercontent.com/mem0ai/mem0/main/openmemory/run.sh | bash
```

This starts:
- **OpenMemory API** at `http://localhost:8765`
- **OpenMemory Dashboard** at `http://localhost:3000`

> **Note:** Data is stored in the container. For persistent storage, follow the manual setup below.

### Manual Setup (Production)

<Steps>
<Step title="Clone the repository">
```bash
git clone https://github.com/mem0ai/mem0.git
cd mem0/openmemory
```
</Step>

<Step title="Configure environment variables">
Create `.env` files in the api and ui directories:

**api/.env:**
```bash
OPENAI_API_KEY=sk-xxx
USER=your-user-id
```

**ui/.env:**
```bash
NEXT_PUBLIC_API_URL=http://localhost:8765
NEXT_PUBLIC_USER_ID=your-user-id
```
</Step>

<Step title="Build and start">
```bash
make build  # Build MCP server and UI
make up     # Start OpenMemory services
```

Access:
- **API:** http://localhost:8765 (docs at /docs)
- **Dashboard:** http://localhost:3000
</Step>
</Steps>

### Connect Your MCP Client

After local setup, connect your client:

```bash
npx @openmemory/install local "http://localhost:8765/mcp/cursor/sse/your-username" --client cursor
```

Replace:
- `your-username` with your actual username
- `cursor` with your client (claude, windsurf, etc.)

## Additional Resources

- **[GitHub Repository](https://github.com/mem0ai/mem0/tree/main/openmemory)** - Source code and issues
- **[MCP Specification](https://spec.modelcontextprotocol.io/)** - Learn about Model Context Protocol
- **[Mem0 Platform](/platform/quickstart)** - Explore the hosted Mem0 Platform alternative
